![SWoOZ (Super Wizard of OZ)](http://i.imgur.com/RHBTY0F.jpg "SWoOZ")

Description :
-------------

SWoOz is a software platform written in C++ used for behavioral experiments based on interactions between people and robots or 3D avatars.


Links :
-------

 * [Website](http://swooz.free.fr/)
 * [Wiki(in progress)](https://github.com/GuillaumeGibert/swooz/wiki)
 * Videos :
    * [Robotic teleoperation](https://github.com/GuillaumeGibert/swooz/wiki/videos_teleop)
    * [Avatars](https://github.com/GuillaumeGibert/swooz/wiki/videos_avatars)

 * Getting started  :
    * [How to build with the scripts](https://github.com/GuillaumeGibert/swooz/blob/master/scripts/README_SCRIPTS.md)
    * [Releases](https://github.com/GuillaumeGibert/swooz/wiki/releases)
    * [Doc doxygen](https://08e729ee992f921ade589fc6589c5f6ffb64b65a.googledrive.com/host/0BywmJqNNU7owTEhFVTRfUzZVSWs/index.html)
    * [Resources](https://github.com/GuillaumeGibert/swooz/wiki/resources)
    

Content :
---------
 * A toolkit for working with tracking devices :
   * interfaces (Kinect/Xtion, Leap, FaceLab, Fastrak Polhemus, Tobii, Sony hmz,...)
 * Modules based on yarp :
   * Tracking human movements without intrusive devices : head, gaze, face, torso, arms, hands, fingers
   * Teleoperation for iCub, NAO, 3D Avatars based on the tracking modules
   * Manipulation for manipulating tracking data and create planifications
   * Feedback for getting video, audio feedback from the robot
 * Avatar creation/morphing :
   * Creation from depths sensors devices(Kinect/Xtion) data
   * Morphing for fitting references avatars meshes
   * Animation/Viewer  

<!---
![](http://uppix.net/GuA0bAs.jpg) ![](http://uppix.net/CKLxdcs.jpg) ![](http://uppix.net/r5JVoTs.jpg) ![](http://uppix.net/gkMAQWs.jpg) ![](http://uppix.net/Qyp88ds.png) ![](http://uppix.net/kgWN89s.jpg)
![](http://uppix.net/2RndHKs.jpg) ![](http://uppix.net/194DGks.jpg)
-->


Research :
----------

SWoOZ is a research project funded by the program "Retour Post-Doctorants" of l'Agence Nationale de la Recherche (ANR) during 3 years.
The originality of this project relies on the full control of avatars' and/or robots' behaviours by a human becoming a puppeteer. 

The project will have two clear phases :

 * during the first phase (year 1, 2012), we are going to develop an open source research platform. This platform will consist of sensors able to track human motion in 3D, software programs to convert motion into articulatory parameters and avatars and robots mimicking accurately and in real-time a confederateâ€™s behaviours. The platform will be delivered as an open-source software at the end of the project.
 * during the second phase (year 2 and 3, 2013-2014), a series of behavioural and neuroimaging experiments will be conducted to investigate several aspects of human-machine interaction.




